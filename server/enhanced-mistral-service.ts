import fetch from 'node-fetch';

interface MistralRequest {
  model: string;
  messages: Array<{
    role: 'user' | 'assistant' | 'system';
    content: string;
  }>;
  temperature?: number;
  max_tokens?: number;
  top_p?: number;
  stream?: boolean;
  safe_prompt?: boolean;
}

interface MistralResponse {
  success: boolean;
  content?: string;
  error?: string;
  model: string;
  tokensUsed?: number;
  finishReason?: string;
  metadata?: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
  };
}

export class EnhancedMistralService {
  private apiKey: string;
  private baseURL = 'https://api.mistral.ai/v1';
  
  constructor() {
    this.apiKey = process.env.MISTRAL_API_KEY || '';
  }

  async generateContent(request: {
    prompt: string;
    model?: string;
    temperature?: number;
    maxTokens?: number;
    systemPrompt?: string;
  }): Promise<MistralResponse> {
    try {
      if (!this.apiKey) {
        throw new Error('Mistral API key not configured');
      }

      const model = request.model || 'mistral-large-latest';
      
      const messages = [];
      
      if (request.systemPrompt) {
        messages.push({
          role: 'system' as const,
          content: request.systemPrompt
        });
      }
      
      messages.push({
        role: 'user' as const,
        content: request.prompt
      });

      const payload: MistralRequest = {
        model,
        messages,
        temperature: request.temperature || 0.7,
        max_tokens: request.maxTokens || 2048,
        top_p: 0.9,
        safe_prompt: false
      };

      console.log('ü§ñ Mistral AI: Generating content with model:', model);

      const response = await fetch(`${this.baseURL}/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`
        },
        body: JSON.stringify(payload)
      });

      if (!response.ok) {
        const errorData = await response.text();
        throw new Error(`Mistral API error: ${response.status} - ${errorData}`);
      }

      const data = await response.json() as any;
      
      if (data.choices && data.choices[0]) {
        const choice = data.choices[0];
        const usage = data.usage || {};
        
        console.log('‚úÖ Mistral AI: Content generated successfully');
        
        return {
          success: true,
          content: choice.message.content,
          model,
          tokensUsed: usage.total_tokens || 0,
          finishReason: choice.finish_reason,
          metadata: {
            promptTokens: usage.prompt_tokens || 0,
            completionTokens: usage.completion_tokens || 0,
            totalTokens: usage.total_tokens || 0
          }
        };
      }

      throw new Error('No content generated by Mistral AI');
      
    } catch (error) {
      console.error('‚ùå Mistral AI generation error:', error);
      return {
        success: false,
        error: error instanceof Error ? error.message : 'Mistral AI generation failed',
        model: request.model || 'mistral-large-latest'
      };
    }
  }

  async generateCopywriting(prompt: string, options: {
    style?: 'professional' | 'casual' | 'persuasive' | 'technical';
    tone?: 'formal' | 'friendly' | 'urgent' | 'calm';
    length?: 'short' | 'medium' | 'long';
    target?: string;
  } = {}): Promise<MistralResponse> {
    const {
      style = 'professional',
      tone = 'friendly',
      length = 'medium',
      target = 'p√∫blico geral'
    } = options;

    const lengthInstructions = {
      short: 'Mantenha o texto conciso, m√°ximo 200 palavras.',
      medium: 'Desenvolva o conte√∫do de forma completa, entre 300-500 palavras.',
      long: 'Crie um texto detalhado e abrangente, entre 600-1000 palavras.'
    };

    const systemPrompt = `Voc√™ √© um especialista em copywriting e marketing digital. 
Crie conte√∫do ${style} com tom ${tone} para ${target}.
${lengthInstructions[length]}
Foque em:
- Headlines impactantes
- Calls-to-action efetivos
- Linguagem persuasiva
- Estrutura clara e envolvente
Responda em portugu√™s brasileiro.`;

    return this.generateContent({
      prompt,
      systemPrompt,
      temperature: 0.8,
      maxTokens: length === 'long' ? 3000 : length === 'medium' ? 2000 : 1000
    });
  }

  async generateProductStrategy(prompt: string, options: {
    industry?: string;
    marketSize?: 'local' | 'nacional' | 'internacional';
    budget?: 'baixo' | 'm√©dio' | 'alto';
    timeline?: 'curto' | 'm√©dio' | 'longo';
  } = {}): Promise<MistralResponse> {
    const {
      industry = 'tecnologia',
      marketSize = 'nacional',
      budget = 'm√©dio',
      timeline = 'm√©dio'
    } = options;

    const systemPrompt = `Voc√™ √© um consultor estrat√©gico especializado em desenvolvimento de produtos e estrat√©gia de mercado.
Analise para a ind√∫stria de ${industry}, mercado ${marketSize}, or√ßamento ${budget} e prazo ${timeline}.

Estruture sua resposta com:
1. An√°lise de Mercado
2. Posicionamento do Produto
3. Estrat√©gia de Pre√ßos
4. Plano de Lan√ßamento
5. M√©tricas de Sucesso
6. Riscos e Mitiga√ß√µes

Seja espec√≠fico, pr√°tico e baseado em dados de mercado atuais.
Responda em portugu√™s brasileiro.`;

    return this.generateContent({
      prompt,
      systemPrompt,
      temperature: 0.6,
      maxTokens: 3000
    });
  }

  async generateTrafficStrategy(prompt: string, options: {
    platforms?: string[];
    budget?: number;
    objective?: 'awareness' | 'conversions' | 'engagement' | 'leads';
    audience?: string;
  } = {}): Promise<MistralResponse> {
    const {
      platforms = ['Facebook', 'Google', 'Instagram'],
      budget,
      objective = 'conversions',
      audience = 'adultos 25-45 anos'
    } = options;

    const budgetText = budget ? `com or√ßamento de R$ ${budget}` : 'com or√ßamento otimizado';

    const systemPrompt = `Voc√™ √© um especialista em tr√°fego pago e marketing digital.
Crie estrat√©gia para ${platforms.join(', ')} focando em ${objective} para ${audience} ${budgetText}.

Estruture com:
1. Estrat√©gia por Plataforma
2. Segmenta√ß√£o de P√∫blico
3. Tipos de Campanhas
4. Or√ßamento e Lances
5. Criativos Recomendados
6. M√©tricas e KPIs
7. Otimiza√ß√µes Cont√≠nuas

Inclua exemplos pr√°ticos e configura√ß√µes espec√≠ficas.
Responda em portugu√™s brasileiro.`;

    return this.generateContent({
      prompt,
      systemPrompt,
      temperature: 0.7,
      maxTokens: 3000
    });
  }

  async generateAnalyticsInsights(prompt: string, options: {
    dataType?: 'website' | 'social' | 'ads' | 'sales';
    timeframe?: 'daily' | 'weekly' | 'monthly' | 'quarterly';
    metrics?: string[];
  } = {}): Promise<MistralResponse> {
    const {
      dataType = 'website',
      timeframe = 'monthly',
      metrics = ['convers√µes', 'tr√°fego', 'ROI']
    } = options;

    const systemPrompt = `Voc√™ √© um analista de dados especializado em marketing digital e business intelligence.
Analise dados de ${dataType} com per√≠odo ${timeframe} focando em ${metrics.join(', ')}.

Estruture a an√°lise com:
1. Resumo Executivo
2. Principais KPIs
3. Tend√™ncias Identificadas
4. Insights Acion√°veis
5. Recomenda√ß√µes Estrat√©gicas
6. Dashboard Sugerido
7. Pr√≥ximos Passos

Use uma abordagem data-driven com interpreta√ß√µes pr√°ticas.
Responda em portugu√™s brasileiro.`;

    return this.generateContent({
      prompt,
      systemPrompt,
      temperature: 0.5,
      maxTokens: 2500
    });
  }

  async listAvailableModels(): Promise<string[]> {
    try {
      const response = await fetch(`${this.baseURL}/models`, {
        method: 'GET',
        headers: {
          'Authorization': `Bearer ${this.apiKey}`
        }
      });

      if (!response.ok) {
        throw new Error(`Failed to fetch models: ${response.status}`);
      }

      const data = await response.json() as any;
      return data.data?.map((model: any) => model.id) || [
        'mistral-tiny',
        'mistral-small', 
        'mistral-medium',
        'mistral-large-latest'
      ];
    } catch (error) {
      console.error('Error fetching Mistral models:', error);
      return ['mistral-large-latest']; // fallback
    }
  }

  async generateStructuredContent(prompt: string, structure: 'json' | 'markdown' | 'html' = 'markdown'): Promise<MistralResponse> {
    const formatInstructions = {
      json: 'Responda em formato JSON v√°lido com estrutura clara.',
      markdown: 'Responda em formato Markdown bem estruturado com headers, listas e formata√ß√£o.',
      html: 'Responda em HTML sem√¢ntico e bem formatado.'
    };

    const systemPrompt = `Voc√™ √© um gerador de conte√∫do estruturado especializado.
${formatInstructions[structure]}
Mantenha a qualidade e relev√¢ncia do conte√∫do.
Responda em portugu√™s brasileiro.`;

    return this.generateContent({
      prompt,
      systemPrompt,
      temperature: 0.6,
      maxTokens: 2500
    });
  }
}

export const enhancedMistralService = new EnhancedMistralService();